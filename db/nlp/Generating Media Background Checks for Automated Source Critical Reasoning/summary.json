{"abstract": "This paper introduces the task of media background check generation, a novel task in natural language processing (NLP) where models summarize information about media sources to enable critical analysis. The authors propose a dataset of 6,709 examples collected from the Media Bias / Fact Check website and investigate several baselines for the task, including open-source and closed-source large language models (LLMs). The findings demonstrate that retrieval-augmentation can greatly improve performance and that open-source models are highly competitive on this difficult task. The human evaluation gives strong evidence that media background checks are helpful for humans when evaluating media sources and helpful for models when generating answers based on retrieved sources.", "introduction": "When humans perform knowledge-intensive reasoning, we are rarely able to rely on a single, authoritative source. Instead, we forage for multiple sources, evaluate their trustworthiness, and synthesize answers (Potter, 2013). Best practice for epistemic experts, such as journalists and historians, is to rely on multiple sources, to present evidence of source tendency and reliability, and to explain source disagreements to readers (Steensen, 2019). Search engines, acting as surrogate experts (Simpson, 2013), similarly enrich their results with knowledge-contexts that help users reason about tendency and trust (Smith and Rieh, 2019). No, that is disinformation created to justify sanctions.", "future_direction": "The proposed media background checks can be used to determine which documents can be relied on for further reasoning and to craft reliable narratives based on untrustworthy evidence. The authors suggest that generated background checks can supplement human-written background checks in cases where the latter are incomplete or lack crucial information. The model can also be used to provide confidence in the answer when sources are untrustworthy, and to obtain confidence in the answer when sources are trustworthy. Another possible solution could be an interactive system that allows users to expand background checks in a desired direction.", "research_gap": "The authors identify the following research gaps: (1) the current state of the art in source-critical reasoning is limited, and there is a need for more research in this area; (2) the proposed method requires additional evidence to establish trust, which may not be available in all cases; (3) the model may not be able to capture complex relationships between sources and may require additional data to improve its performance.", "conclusion": "The authors conclude that the proposed media background checks are a useful tool for humans and models to reason source-critically. The human evaluation gives strong evidence that media background checks are helpful for humans when evaluating media sources and helpful for models when generating answers based on retrieved sources. The authors suggest that generated background checks can supplement human-written background checks in cases where the latter are incomplete or lack crucial information."}